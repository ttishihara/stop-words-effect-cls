{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```text\n",
      "=== Software === \n",
      "python        : 3.6.5\n",
      "fastai        : 1.0.52\n",
      "fastprogress  : 0.1.21\n",
      "torch         : 1.1.0\n",
      "nvidia driver : 418.40\n",
      "torch cuda    : 10.0.130 / is available\n",
      "torch cudnn   : 7501 / is enabled\n",
      "\n",
      "=== Hardware === \n",
      "nvidia gpus   : 1\n",
      "torch devices : 1\n",
      "  - gpu0      : 11441MB | Tesla K80\n",
      "\n",
      "=== Environment === \n",
      "platform      : Linux-4.4.0-1084-aws-x86_64-with-debian-stretch-sid\n",
      "distro        : #94-Ubuntu SMP Fri May 17 13:10:20 UTC 2019\n",
      "conda env     : Unknown\n",
      "python        : /home/ubuntu/anaconda3/bin/python\n",
      "sys.path      : \n",
      "/home/ubuntu/src/cntk/bindings/python\n",
      "/home/ubuntu/anaconda3/lib/python36.zip\n",
      "/home/ubuntu/anaconda3/lib/python3.6\n",
      "/home/ubuntu/anaconda3/lib/python3.6/lib-dynload\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/extensions\n",
      "/home/ubuntu/.ipython\n",
      "```\n",
      "\n",
      "Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n",
      "\n",
      "Optional package(s) to enhance the diagnostics can be installed with:\n",
      "pip install distro\n",
      "Once installed, re-run this utility to get the additional information\n"
     ]
    }
   ],
   "source": [
    "import fastai.utils.collect_env\n",
    "\n",
    "fastai.utils.collect_env.show_install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preparing the data (on a sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ubuntu/.fastai/data/imdb/cl_nltk_databunch'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/unsup'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/lm_nltk_databunch'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/lm_sklearn_databunch'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/lm_spacy_databunch'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/test'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/cl_sklearn_databunch'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/lm_full_databunch'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/cl_full_databunch'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/models'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/cl_spacy_databunch')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ubuntu/.fastai/data/imdb/train/pos'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/train/neg'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imdb/train/labeledBow.feat')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating custom tokenizer for removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_nltk(text:Collection[str]):\n",
    "    from nltk.corpus import stopwords \n",
    "    stop_words_nltk = stopwords.words('english')\n",
    "    text_filt = []\n",
    "    for word in text:\n",
    "        if word not in stop_words_nltk:\n",
    "            text_filt.append(word)\n",
    "    return text_filt\n",
    "\n",
    "\n",
    "def remove_stop_words_spacy(text:Collection[str]):\n",
    "#     import spacy\n",
    "#     nlp = spacy.load(\"en_core_web_sm\")\n",
    "    stop_words_spacy = {'however', 'our', 'onto', 'the', 'is', 'so', 'us', 'upon', 'while', 'as', 'why', 'below', 'only', 'herself', 'already', 'fifteen', 'under', 'whole', 'few', 'empty', 'used', 'many', 'top', 'seeming', 'to', 'there', 'alone', 'or', 'therein', 'thru', 'enough', 'never', 'ca', 'an', 'but', 'do', 'other', 'everywhere', 'rather', 'than', 'anything', 'once', 'less', 'nowhere', 'more', 'back', 'within', 'cannot', 'into', 'did', 'hence', 'last', 'itself', 'behind', 'elsewhere', 'seems', 'toward', 'indeed', 'it', 'thus', 'well', 'much', 'whereafter', 'whether', 'which', 'between', 'beside', 'always', 'please', 'nine', 'seemed', 'could', 'sometime', 'another', 'ourselves', 'against', 'wherein', 'eight', 'been', 'again', 'and', 'ours', 'themselves', 'two', 'across', 'either', 'neither', 'often', 'perhaps', 'out', 'by', 'nobody', 'others', 'those', 'whenever', 'mine', 'former', 'eleven', 'any', 'anyhow', 'call', 'myself', 'of', 're', 'same', 'their', 'third', 'anyway', 'along', 'hereupon', 'hereby', 'meanwhile', 'my', 'one', 'per', 'yourselves', 'using', 'were', 'whatever', 'somehow', 'except', 'whereupon', 'down', 'five', 'should', 'although', 'whereby', 'i', 'give', 'among', 'almost', 'doing', 'go', 'around', 'something', 'every', 'full', 'keep', 'might', 'must', 'whither', 'hers', 'besides', 'because', 'done', 'if', 'since', 'most', 'a', 'various', 'whose', 'your', 'his', 'beyond', 'ever', 'would', 'make', 'hundred', 'whereas', 'move', 'regarding', 'at', 'can', 'without', 'had', 'wherever', 'are', 'her', 'still', 'be', 'no', 'name', 'through', 'what', 'put', 'himself', 'thereupon', 'these', 'above', 'before', 'anywhere', 'whoever', 'this', 'them', 'someone', 'me', 'latter', 'over', 'from', 'until', 'whence', 'then', 'in', 'thereafter', 'unless', 'six', 'herein', 'during', 'somewhere', 'due', 'seem', 'with', 'has', 'sixty', 'further', 'such', 'that', 'namely', 'none', 'also', 'who', 'four', 'we', 'all', 'very', 'he', 'being', 'may', 'nevertheless', 'fifty', 'whom', 'some', 'about', 'serious', 'will', 'else', 'therefore', 'twenty', 'you', 'yours', 'where', 'next', 'she', 'take', 'becomes', 'amount', 'least', 'even', 'was', 'for', 'have', 'nor', 'really', 'when', 'otherwise', 'afterwards', 'am', 'how', 'after', 'its', 'throughout', 'now', 'everyone', 'bottom', 'together', 'moreover', 'becoming', 'mostly', 'quite', 'forty', 'see', 'hereafter', 'thereby', 'too', 'here', 'first', 'yourself', 'each', 'everything', 'up', 'via', 'part', 'say', 'they', 'both', 'noone', 'own', 'though', 'him', 'amongst', 'became', 'become', 'beforehand', 'front', 'latterly', 'thence', 'made', 'yet', 'sometimes', 'anyone', 'get', 'towards', 'nothing', 'on', 'does', 'formerly', 'show', 'ten', 'three', 'several', 'just', 'side', 'not', 'off', 'twelve'}\n",
    "    text_filt = []\n",
    "    for word in text:\n",
    "        if word not in stop_words_spacy:\n",
    "            text_filt.append(word)\n",
    "    return text_filt\n",
    "\n",
    "\n",
    "def remove_stop_words_sklearn(text:Collection[str]):\n",
    "    from sklearn.feature_extraction import stop_words\n",
    "    stop_words_sklearn = stop_words.ENGLISH_STOP_WORDS\n",
    "    text_filt = []\n",
    "    for word in text:\n",
    "        if word not in stop_words_sklearn:\n",
    "            text_filt.append(word)\n",
    "    return text_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_rules_nltk = [remove_stop_words_nltk] + defaults.text_post_rules\n",
    "custom_rules_spacy = [remove_stop_words_spacy] + defaults.text_post_rules\n",
    "custom_rules_sklearn = [remove_stop_words_sklearn] + defaults.text_post_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_nltk = Tokenizer(post_rules=custom_rules_nltk)\n",
    "tokenizer_spacy = Tokenizer(post_rules=custom_rules_spacy)\n",
    "tokenizer_sklearn = Tokenizer(post_rules=custom_rules_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating databunch for language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm_nltk = (TextList.from_folder(path, \n",
    "                                     processor=[OpenFileProcessor(), \n",
    "                                                TokenizeProcessor(tokenizer=tokenizer_nltk), \n",
    "                                                NumericalizeProcessor()])\n",
    "                .use_partial_data(0.2, seed=42)\n",
    "               #Inputs: all the text files in path\n",
    "                .filter_by_folder(include=['train', 'test', 'unsup']) \n",
    "               #We may have other temp folders that contain text files so we only keep what's in train and test\n",
    "                .split_by_rand_pct(0.1, seed=42)\n",
    "               #We randomly split and keep 10% (10,000 reviews) for validation\n",
    "                .label_for_lm()           \n",
    "               #We want to do a language model so we label accordingly\n",
    "                .databunch(bs=bs, num_workers=1))\n",
    "data_lm_nltk.save('lm_nltk_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_lm_sklearn = (TextList.from_folder(path, \n",
    "                                     processor=[OpenFileProcessor(), \n",
    "                                                TokenizeProcessor(tokenizer=tokenizer_sklearn), \n",
    "                                                NumericalizeProcessor()])\n",
    "                .use_partial_data(0.2, seed=42)\n",
    "                .filter_by_folder(include=['train', 'test', 'unsup']) \n",
    "                .split_by_rand_pct(0.1, seed=42)\n",
    "                .label_for_lm()           \n",
    "                .databunch(bs=bs, num_workers=-1))\n",
    "\n",
    "data_lm_sklearn.save('lm_sklearn_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm_spacy = (TextList.from_folder(path, \n",
    "                                     processor=[OpenFileProcessor(), \n",
    "                                                TokenizeProcessor(tokenizer=tokenizer_spacy), \n",
    "                                                NumericalizeProcessor()])\n",
    "                .use_partial_data(0.2, seed=42)\n",
    "                .filter_by_folder(include=['train', 'test', 'unsup']) \n",
    "                .split_by_rand_pct(0.1, seed=42)\n",
    "                .label_for_lm()           \n",
    "                .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "\n",
    "data_lm_spacy.save('lm_spacy_databunch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm_full = (TextList.from_folder(path)\n",
    "                .use_partial_data(0.2, seed=42)\n",
    "                .filter_by_folder(include=['train', 'test', 'unsup']) \n",
    "                .split_by_rand_pct(0.1, seed=42)\n",
    "                .label_for_lm()           \n",
    "                .databunch(bs=bs, num_workers=-1))\n",
    "\n",
    "data_lm_full.save('lm_full_databunch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating databunches for classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl_nltk = (TextList.from_folder(path, vocab=data_lm_nltk.vocab, \n",
    "                                     processor=[OpenFileProcessor(), \n",
    "                                                TokenizeProcessor(tokenizer=tokenizer_nltk), \n",
    "                                                NumericalizeProcessor()])\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "data_cl_nltk.save('cl_nltk_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl_spacy = (TextList.from_folder(path, vocab=data_lm_spacy.vocab)\n",
    "             .split_by_folder(valid='test')\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "data_cl_spacy.save('cl_spacy_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl_sklearn = (TextList.from_folder(path, vocab=data_lm_sklearn.vocab)\n",
    "             .split_by_folder(valid='test')\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "data_cl_sklearn.save('cl_sklearn_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl_full = (TextList.from_folder(path, vocab=data_lm_full.vocab)\n",
    "             .split_by_folder(valid='test')\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             .databunch(bs=bs, num_workers=1))\n",
    "\n",
    "data_cl_full.save('cl_full_databunch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load databunches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm_nltk = load_data(path, 'lm_nltk_databunch')\n",
    "data_lm_spacy = load_data(path, 'lm_spacy_databunch')\n",
    "data_lm_sklearn = load_data(path, 'lm_sklearn_databunch')\n",
    "data_lm_full = load_data(path, 'lm_full_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl_nltk = load_data(path, 'cl_nltk_databunch')\n",
    "data_cl_spacy = load_data(path, 'cl_spacy_databunch')\n",
    "data_cl_sklearn = load_data(path, 'cl_sklearn_databunch')\n",
    "data_cl_full = load_data(path, 'cl_full_databunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxmaj german - speaking countries ) , xxmaj xxunk seen traditional backward region . xxmaj and actors helpless alien women . xxmaj well , films people unable deal women like \" xxmaj american xxmaj pie \" series . \\n \\n  xxmaj but film achieved true , funny weirdness . xxmaj you constantly wonder came crackpot ideas . xxmaj but 1974 , looking back 35 years fills one kind nostalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>action , without toning gory moments children , made amazing ! xxmaj this sad day movie genres . xxmaj originality dead . xxmaj people hail horror movies like xxmaj the xxmaj descent xxmaj the xxmaj mist , ignoring fact 95 % movies could copy / pasted last monster movie held run . xxmaj the fact movie takes clichés actually laughs face , i ca n't help enjoy . xxmaj people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>self . xxmaj contrastingly , xxmaj giamatti gives us younger , xxunk mope . xxmaj the comics give us varied pictures -- depends cartoonist . \\n \\n  xxmaj pekar , played xxmaj giamatti , lackluster protagonist ; 's obsessive - compulsive neurotic whines virtues everyman . xxmaj he 's repulsive -- home mess scratches head incessantly . xxmaj he try new shampoo conditioner , perhaps n't wash often .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ending luscious . xxmaj check one form opinion . i give picture 7 10 . xxbos xxmaj loosely based upon life xxmaj janis xxmaj joplin struggles fame drugs , xxmaj rose stays viewer long final fadeout . xxmaj acting tour - de - forces manifest everywhere , although virtually entire supporting cast brings xxmaj broadway - style truth urgency make thus excellent . xxbos xxmaj what say film makes \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3 lousy writing , poor technical merit continuity problems . xxmaj some people given movie 10 - -and perhaps okay simply scoring fun factor . xxmaj however , technically inept movie serial start finish -- produced 3rd - rate writers , actors crew . xxmaj that really true nearly serials meant low - brow entertainment particularly aimed kids . xxmaj and 's nothing wrong , \" high art \" ai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm_nltk.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn_lm_nltk = language_model_learner(data_lm_nltk, AWD_LSTM, drop_mult=0.3).to_fp16()\n",
    "learn_lm_spacy = language_model_learner(data_lm_spacy, AWD_LSTM, drop_mult=0.3).to_fp16()\n",
    "learn_lm_sklearn = language_model_learner(data_lm_sklearn, AWD_LSTM, drop_mult=0.3).to_fp16()\n",
    "learn_lm_full = language_model_learner(data_lm_full, AWD_LSTM, drop_mult=0.3).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr *= bs/48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.378191</td>\n",
       "      <td>5.245024</td>\n",
       "      <td>0.234844</td>\n",
       "      <td>10:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm_nltk.fit_one_cycle(1, lr*10, moms=(0.8,0.7))\n",
    "learn_lm_nltk.save('fit_1_nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.381940</td>\n",
       "      <td>5.227905</td>\n",
       "      <td>0.244304</td>\n",
       "      <td>10:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm_spacy.fit_one_cycle(1, lr*10, moms=(0.8,0.7))\n",
    "learn_lm_spacy.save('fit_1_spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.389753</td>\n",
       "      <td>5.214949</td>\n",
       "      <td>0.244041</td>\n",
       "      <td>10:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm_sklearn.fit_one_cycle(1, lr*10, moms=(0.8,0.7))\n",
    "learn_lm_sklearn.save('fit_1_sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.207071</td>\n",
       "      <td>4.026411</td>\n",
       "      <td>0.290705</td>\n",
       "      <td>16:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm_full.fit_one_cycle(1, lr*10, moms=(0.8,0.7))\n",
    "learn_lm_full.save('fit_1_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (18000 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj why do i give this 1974 porn movie 7 points ? xxmaj because i watched it . xxmaj and i found it hilarious ! xxmaj aliens , their weird spaceship , their weird helmets ... my xxmaj god , was that a sight . xxmaj and all what these desperate alien women need is semen from the earth . \n",
       " \n",
       "  xxmaj and where do they look for it ? xxmaj in upper xxmaj xxunk , xxmaj germany . xxmaj and that is where the main fun comes from : xxmaj in xxmaj europe ( and more so in xxmaj german - speaking countries ) , xxmaj xxunk is seen as a traditional and backward region . xxmaj and then the actors are so helpless with the alien women . xxmaj well , there have been films about people being unable to deal with women like the \" xxmaj american xxmaj pie \" series . \n",
       " \n",
       "  xxmaj but what this film achieved is a true , funny weirdness . xxmaj you constantly wonder how they came up with these crackpot ideas . xxmaj but it was 1974 , and looking back 35 years fills one with a kind of nostalgia . xxmaj you 've never seen a film like that . \n",
       " \n",
       "  xxmaj and if you do n't mind seeing the casual pubic hairs and breasts , watch it once . xxmaj it is a comedy essentially , not a porn flick .,xxbos xxmaj this film biography of early rock and roll star xxmaj buddy xxmaj holly ( 1936 - 1959 ) is a tour de force for xxmaj gary xxmaj busey . xxmaj the movie 's highlights are xxmaj busey 's stage performances where he plays guitar and sings xxmaj holly songs . xxmaj he brings such energy to the performances that xxmaj holly 's own filmed performances almost pale in comparison . xxmaj busey 's infectious xxunk grin lights up the screen , he creates a totally believable and winning personality and his xxmaj oscar nomination for best actor was well deserved . \n",
       " \n",
       "  xxmaj the film follows xxmaj holly 's career from growing up in xxmaj xxunk , xxmaj texas , to stardom and xxmaj new xxmaj york and his untimely death in a plane crash . xxmaj one thing i found interesting , if true , was xxmaj buddy 's driving ambition -- he had great plans to go beyond recording and performance to producing . xxmaj as young as he was he was already establishing himself as a shrewd businessman and definitely wanted to take things to a higher level . xxmaj we will never know if he would have ultimately catapulted his early success into a business brand like xxmaj the xxmaj rolling xxmaj stones . \n",
       " \n",
       "  xxmaj the lyrics of many of xxmaj holly 's songs are pretty adolescent ; read the lyrics for \" xxmaj peggy xxmaj sue \" or \" xxmaj oh xxmaj boy ! \" and you will see what i mean . xxmaj maybe to a great extent this explains his popularity with adolescent audiences , but his xxunk and stage performances surely account for his influence on groups to follow -- both xxmaj the xxmaj rolling xxmaj stones and xxmaj the xxmaj beatles have acknowledged his importance . \n",
       " \n",
       "  xxmaj clearly some liberties were taken for dramatic effect . xxmaj for example , i doubt that xxmaj holly ever punched out a producer in xxmaj nashville or that the audience at xxmaj new xxmaj york 's xxmaj apollo theater was so immediately xxunk as to be wildly dancing in the aisles . xxmaj if you are interested in getting closer to the truth , see the documentary \" xxmaj the xxmaj real xxmaj buddy xxmaj holly xxmaj story \" ( 1985 ) that is produced and hosted by a very relaxed and engaging xxmaj paul mccartney . xxmaj this contains interviews with xxmaj holly 's family , friends , and band - mates ( xxmaj holly 's musical brothers are not even mentioned in \" xxmaj the xxmaj buddy xxmaj holly xxmaj story \" ) . xxmaj members of other bands like xxmaj keith xxmaj richards and xxmaj don xxmaj everly also offer opinions and stories and there is footage of old xxmaj holly performances . xxmaj the mccartney production can stand on its own , but it makes an excellent companion piece to \" xxmaj the xxmaj buddy xxmaj holly xxmaj story \" and perhaps should be required viewing for anyone who watches the fictionalized story .,xxbos xxmaj now living in the late 1970 's , a former army xxmaj colonel / xxmaj scientist xxmaj robert xxmaj neville ( xxmaj oscar - xxmaj winner : xxmaj charleton xxmaj heston ) is living in a deserted xxmaj los xxmaj angeles . xxmaj after surviving a disastrous plague , which it 's been several years that xxmaj robert is alone and he thinks he is the only man alive in the entire world . xxmaj but when it turns dark outside ... there 's a group of cultists who called themselves \" xxmaj the xxmaj family \" ( xxmaj led by xxmaj anthony xxmaj zerbe ) , who got affected by the plague . \" xxmaj the xxmaj family \" are xxunk mutants , who ca n't be outside during the day expect night - time . xxmaj they also are trying to destroyed every technology or human , they could find . xxmaj which xxmaj robert battles with these freaks of nature nearly every night to survive . xxmaj but xxmaj robert finds out , he is not alone in the city . xxmaj when he meets a tough survivor xxmaj lisa ( xxmaj xxunk xxmaj cash ) and other humans are not turned by the virus . xxmaj now xxmaj robert finds another chance to find a cure against these monsters . xxmaj before it 's too late . \n",
       " \n",
       "  xxmaj directed by xxmaj boris xxmaj segal made an intriguing xxmaj science xxmaj fiction movie that has moments of action , suspense and some moments of comedy . xxmaj segal 's film is also visually striking , especially the wide empty streets of xxup l.a. but unfortunately the feature has some incredibly campy moments at rather tense sequences . xxmaj heston is very good at his role here . xxmaj which it is one of the reasons why \" xxmaj the xxmaj omega xxmaj man \" remain memorable for over the years . xxmaj although this is the second version of \" i xxmaj am xxmaj legend \" , xxmaj based on a novel by xxmaj richard xxmaj matheson ( xxmaj duel , a xxmaj stir of xxmaj echoes , xxmaj what xxmaj dreams xxmaj may xxmaj come ) . xxmaj first version was done in the 1960 's titled \" xxmaj the xxmaj last xxmaj man on xxmaj earth \" starring xxmaj vincent xxmaj price and last year 's \" i xxmaj am xxmaj legend \" starring xxmaj will xxmaj smith . xxmaj which these three films has the same premise but done completely different . xxmaj the book also inspired filmmaker xxmaj george xxup a. xxmaj romero to created flesh eating zombies in the classic \" xxmaj night of the xxmaj living xxmaj dead \" . xxmaj despite some serious flaws , \" xxmaj the xxmaj omega xxmaj man \" is still a good movie . xxmaj for those who are familiar with the recent adaptation \" i xxmaj am xxmaj legend \" and never seen this one . xxmaj this is worth checking out . xxmaj panavision . ( * * * ½ / xxrep 5 * ) .,xxbos xxmaj this movie was a real milestone , it marked the end of xxmaj xxunk 's era . xxmaj like the part one is a snap - shot of 90s , this one is the reflection of , on the one hand , started changes of xxup xxunk internal and external policy . xxmaj of course , partly they were ( as usual ) just proclaimed changes , but it does n't matter in this case because , on the other hand , xxmaj brat-2 showed nation 's feelings and hopes of those days . xxmaj as far as i remember xxmaj xxunk himself said something like \" xxmaj the movie was just the answer to the state of public opinion \" . xxmaj also keep in mind it was time just after aggression of xxup us against xxmaj yugoslavia and time of victories of federal forces in the second xxmaj xxunk war - everyone still remembered the humiliation of the first war as well as all previous decade . xxmaj now you can imagine the eye we watched xxmaj xxunk with . xxmaj and you can understand what we felt \n",
       "  xxmaj the main message of the movie is xxmaj danila 's words : \" xxmaj so i think that the truth is the power : the one who has truth he is stronger \" . xxmaj this phrase has become a xxunk . xxmaj in fact , all the movie is about that : neither xxunk and criminal ( personified as \" xxmaj new xxmaj russians \" and xxmaj ukrainian bandits ) , nor money and hypocrisy ( xxmaj american smooth operators ) can defeat the truth . xxmaj the idea is shown with use of violence . xxmaj this point was subject of much criticism , but it 's certainly not the main thing in the film , at most the decoration for its message . xxmaj if you saw xxmaj brat-2 you would understand me . xxmaj another idea is that you can find good and sincere people in any country , any nation and any order . xxmaj it does n't matter what all damned governments and bigwigs do : good hearts will always find each other in this cruel world . xxmaj in addition , xxmaj brat-2 is full of sentences , including humorous , which became famous : the above - mentioned \" truth \" , \" xxmaj russians never desert their own in the war \" , \" xxmaj you bitches will answer to me for xxmaj xxunk ! \" and many others . \n",
       " \n",
       "  xxmaj so . xxmaj despite some rude episodes i disliked , despite ( i think ) excessive violence shown , i give it 10 of 10 . xxmaj xxunk deserves .,xxbos i 'm a fan of xxmaj columbo , especially on a rainy xxmaj saturday , and it was fun to see xxmaj oskar xxmaj werner after xxmaj fahrenheit xxunk , but this episode was very lacking . xxmaj the original plot and plot twists were obvious and could be guessed way in advance , even years before the modern detective shows of today . xxmaj but it was amusing to see the crazy couch patterns and \" modern \" electronics equipment and , of course , the mandatory suburbanite humor poking fun at modern art for sale . xxmaj the high - tech home is a xxmaj xxunk 's or xxmaj disney version of xxmaj xxunk , and fun to think of writers inventing those \" way - out gizmos \" . \n",
       " \n",
       "  xxmaj if its sunny outside , go play , as there are much better xxmaj columbo episodes . xxmaj still , we should be thankful for xxmaj cable xxup tv that these episodes are being broadcast .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /home/ubuntu/.fastai/data/imdb;\n",
       "\n",
       "Valid: LabelList (1999 items)\n",
       "x: LMTextList\n",
       "xxbos xxup ok , how 's this for xxunk this mean , rich old geezer leaves his estate to his adult children , all of them ungrateful losers , and two creepy servants , provided they spend the week in his spooky old house . xxmaj what happens that night will surprise only those who have n't seen a movie or television show before . xxmaj after a string of murders in which the victims look like they 're bleeding restaurant ketchup , we have a painfully obvious twist ending . xxmaj the cast is lead by some once respectable actors must have been desperate for their paychecks . xxmaj there are also a few second - tier actors who were rising at the time but long forgotten now . xxmaj as a result , the film generates all the drama and mystery of an episode of \" xxmaj matlock . \" i will give credit where it 's xxunk the closing scene is clever and amusing , if you 're still awake .,xxbos i know that i am probably two decades older than the target audience for \" xxmaj one xxmaj tree xxmaj hill \" . i saw this particular episode by accident . i think the subject matter of school shootings is very important . i just wished that the treatment here was more imaginative and , especially the final plot twist at the end of the episode , not so contrived . \n",
       " \n",
       "  xxmaj the only bright spot in this episode was the credible performance of xxmaj colin xxmaj xxunk as xxmaj jimmy xxmaj edwards , the distraught student who held his fellow students hostage . i felt that the actor was on an entirely different level than the others . xxmaj the stars and the supporting cast were very bland and uninteresting . \n",
       " \n",
       "  xxmaj at least with this episode , i kept thinking about how \" xxmaj xxunk : xxmaj the xxmaj next xxmaj generation \" did a much better job than \" xxmaj one xxmaj tree xxmaj hill \" . i noticed that the average age of the actors on \" xxmaj one xxmaj tree xxmaj hill \" is around 23 or 24 years old while the actors on xxmaj xxunk is closer to high school age . xxmaj sometimes when it comes to television shows or movies about teens or young adults , it depends not only on the script but the casting and the talent of the actors .,xxbos yeah its fun and the best xxmaj hitchcock i xxunk hate that xxunk is making it this is the one and only best no 1 i mean no one can change that good suspense and fun 1 for black and white xxmaj while this was n't xxmaj hitchcock 's first feature film , he refers to it as the one that set the pace for his later films , the first to show his vision , style , and bravura . xxmaj the most interesting thing about this film , other than its technical virtuosity and the horribly ineffective soundtrack , is the fact that it was n't supposed to end the way it did . xxmaj hitchcock wanted xxmaj the xxmaj lodger to be the killer , which would have made a more predictable film ( granted in 1926 audiences were n't spoiled by the great of the genre and everything could have been \" surprising \" if the right amount of suspense and tension were provided ) . xxmaj instead , there were pressures to let matinée idol xxmaj xxunk xxmaj novello out of the killer role , probably because people did n't want to picture xxmaj novello as a killer . xxmaj ironically , the fact xxmaj novello would n't end up as the killer made this film even better , a lot more interesting and compelling .,xxbos xxmaj one of my favourite films first saw it when i was about 10 , which probably tells you a lot about the type of humour . xxmaj although dated the humour definitely has a charm about it . xxmaj expect to see the usual xxmaj xxunk & xxmaj murdoch banter so popular in its day , with lots of interesting , quirky co - characters . xxmaj the lady with the parrot , the couple due to get married and are in trouble from ' her ' , and my favourite , the xxunk , \" xxmaj nobody knows where it comes from ... nobody knows where it goes .. \" xxmaj interestingly the ghost train was written by xxmaj arnold xxmaj ridley of xxmaj dads xxmaj army fame ( xxmaj private xxmaj godfrey the medic ) xxmaj watch it on a rainy xxmaj sunday afternoon after your lunch and smile .,xxbos i love xxmaj juan xxmaj piquer - xxmaj xxunk ! xxmaj he 's my absolute favorite bad - movie director and , throughout his whole career , he xxunk tried to cash in on simply every successful contemporary trend in the horror and fantasy genres . xxmaj after the big hit that was \" xxmaj superman \" , xxup xxunk made his own and hilarious \" xxmaj supersonic xxmaj man \" , he picked in on the violent slasher - movie madness with the insane \" xxmaj pieces \" and he really over - xxunk himself with \" xxmaj the xxmaj return of xxup e.t. \" , the unofficial and downright laughable sequel to xxmaj spielberg 's xxup sf - blockbuster . \" xxmaj the xxmaj rift \" is obviously inspired by the series of profitable underwater monster movies like \" xxmaj the xxmaj abyss \" and \" xxmaj xxunk xxmaj six \" . xxmaj from start to finish , you can amuse yourself by spotting all the stolen ideas and shameless rip - offs of these ( and other ) classics . xxmaj when a completely new and fancy type of submarine vanishes near the deep xxmaj xxunk rift , a second mission with u - boat designer xxmaj xxunk xxmaj hayes on board is sent out to investigate what really happened to xxmaj siren xxmaj one . xxmaj in the dark depths of the ocean , the rescue mission discovers an underwater cavern where the government secretly experiments with mutant sea - creatures . xxmaj the monsters are quite aggressive but there 's also the danger of a government enemy among the crew members ... \" xxmaj the xxmaj rift \" is a forgettable film , but it nevertheless has some ingenious  though very dodgy  monster models . xxmaj fans of blood and gore wo n't complain , neither , as the beastly attacks are quite gruesome and merciless . xxmaj the acting is very wooden although many of the cast names can definitely do better . xxmaj it 's xxunk that you simply enjoy the clichés and gory effects in the \" xxmaj the xxmaj rift \" because , if you start contemplating about the screenplay , you 'll find that it makes absolutely no sense .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /home/ubuntu/.fastai/data/imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(33860, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(33860, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=33860, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f34860d9730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/ubuntu/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (18000 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj why do i give this 1974 porn movie 7 points ? xxmaj because i watched it . xxmaj and i found it hilarious ! xxmaj aliens , their weird spaceship , their weird helmets ... my xxmaj god , was that a sight . xxmaj and all what these desperate alien women need is semen from the earth . \n",
       " \n",
       "  xxmaj and where do they look for it ? xxmaj in upper xxmaj xxunk , xxmaj germany . xxmaj and that is where the main fun comes from : xxmaj in xxmaj europe ( and more so in xxmaj german - speaking countries ) , xxmaj xxunk is seen as a traditional and backward region . xxmaj and then the actors are so helpless with the alien women . xxmaj well , there have been films about people being unable to deal with women like the \" xxmaj american xxmaj pie \" series . \n",
       " \n",
       "  xxmaj but what this film achieved is a true , funny weirdness . xxmaj you constantly wonder how they came up with these crackpot ideas . xxmaj but it was 1974 , and looking back 35 years fills one with a kind of nostalgia . xxmaj you 've never seen a film like that . \n",
       " \n",
       "  xxmaj and if you do n't mind seeing the casual pubic hairs and breasts , watch it once . xxmaj it is a comedy essentially , not a porn flick .,xxbos xxmaj this film biography of early rock and roll star xxmaj buddy xxmaj holly ( 1936 - 1959 ) is a tour de force for xxmaj gary xxmaj busey . xxmaj the movie 's highlights are xxmaj busey 's stage performances where he plays guitar and sings xxmaj holly songs . xxmaj he brings such energy to the performances that xxmaj holly 's own filmed performances almost pale in comparison . xxmaj busey 's infectious xxunk grin lights up the screen , he creates a totally believable and winning personality and his xxmaj oscar nomination for best actor was well deserved . \n",
       " \n",
       "  xxmaj the film follows xxmaj holly 's career from growing up in xxmaj xxunk , xxmaj texas , to stardom and xxmaj new xxmaj york and his untimely death in a plane crash . xxmaj one thing i found interesting , if true , was xxmaj buddy 's driving ambition -- he had great plans to go beyond recording and performance to producing . xxmaj as young as he was he was already establishing himself as a shrewd businessman and definitely wanted to take things to a higher level . xxmaj we will never know if he would have ultimately catapulted his early success into a business brand like xxmaj the xxmaj rolling xxmaj stones . \n",
       " \n",
       "  xxmaj the lyrics of many of xxmaj holly 's songs are pretty adolescent ; read the lyrics for \" xxmaj peggy xxmaj sue \" or \" xxmaj oh xxmaj boy ! \" and you will see what i mean . xxmaj maybe to a great extent this explains his popularity with adolescent audiences , but his xxunk and stage performances surely account for his influence on groups to follow -- both xxmaj the xxmaj rolling xxmaj stones and xxmaj the xxmaj beatles have acknowledged his importance . \n",
       " \n",
       "  xxmaj clearly some liberties were taken for dramatic effect . xxmaj for example , i doubt that xxmaj holly ever punched out a producer in xxmaj nashville or that the audience at xxmaj new xxmaj york 's xxmaj apollo theater was so immediately xxunk as to be wildly dancing in the aisles . xxmaj if you are interested in getting closer to the truth , see the documentary \" xxmaj the xxmaj real xxmaj buddy xxmaj holly xxmaj story \" ( 1985 ) that is produced and hosted by a very relaxed and engaging xxmaj paul mccartney . xxmaj this contains interviews with xxmaj holly 's family , friends , and band - mates ( xxmaj holly 's musical brothers are not even mentioned in \" xxmaj the xxmaj buddy xxmaj holly xxmaj story \" ) . xxmaj members of other bands like xxmaj keith xxmaj richards and xxmaj don xxmaj everly also offer opinions and stories and there is footage of old xxmaj holly performances . xxmaj the mccartney production can stand on its own , but it makes an excellent companion piece to \" xxmaj the xxmaj buddy xxmaj holly xxmaj story \" and perhaps should be required viewing for anyone who watches the fictionalized story .,xxbos xxmaj now living in the late 1970 's , a former army xxmaj colonel / xxmaj scientist xxmaj robert xxmaj neville ( xxmaj oscar - xxmaj winner : xxmaj charleton xxmaj heston ) is living in a deserted xxmaj los xxmaj angeles . xxmaj after surviving a disastrous plague , which it 's been several years that xxmaj robert is alone and he thinks he is the only man alive in the entire world . xxmaj but when it turns dark outside ... there 's a group of cultists who called themselves \" xxmaj the xxmaj family \" ( xxmaj led by xxmaj anthony xxmaj zerbe ) , who got affected by the plague . \" xxmaj the xxmaj family \" are xxunk mutants , who ca n't be outside during the day expect night - time . xxmaj they also are trying to destroyed every technology or human , they could find . xxmaj which xxmaj robert battles with these freaks of nature nearly every night to survive . xxmaj but xxmaj robert finds out , he is not alone in the city . xxmaj when he meets a tough survivor xxmaj lisa ( xxmaj xxunk xxmaj cash ) and other humans are not turned by the virus . xxmaj now xxmaj robert finds another chance to find a cure against these monsters . xxmaj before it 's too late . \n",
       " \n",
       "  xxmaj directed by xxmaj boris xxmaj segal made an intriguing xxmaj science xxmaj fiction movie that has moments of action , suspense and some moments of comedy . xxmaj segal 's film is also visually striking , especially the wide empty streets of xxup l.a. but unfortunately the feature has some incredibly campy moments at rather tense sequences . xxmaj heston is very good at his role here . xxmaj which it is one of the reasons why \" xxmaj the xxmaj omega xxmaj man \" remain memorable for over the years . xxmaj although this is the second version of \" i xxmaj am xxmaj legend \" , xxmaj based on a novel by xxmaj richard xxmaj matheson ( xxmaj duel , a xxmaj stir of xxmaj echoes , xxmaj what xxmaj dreams xxmaj may xxmaj come ) . xxmaj first version was done in the 1960 's titled \" xxmaj the xxmaj last xxmaj man on xxmaj earth \" starring xxmaj vincent xxmaj price and last year 's \" i xxmaj am xxmaj legend \" starring xxmaj will xxmaj smith . xxmaj which these three films has the same premise but done completely different . xxmaj the book also inspired filmmaker xxmaj george xxup a. xxmaj romero to created flesh eating zombies in the classic \" xxmaj night of the xxmaj living xxmaj dead \" . xxmaj despite some serious flaws , \" xxmaj the xxmaj omega xxmaj man \" is still a good movie . xxmaj for those who are familiar with the recent adaptation \" i xxmaj am xxmaj legend \" and never seen this one . xxmaj this is worth checking out . xxmaj panavision . ( * * * ½ / xxrep 5 * ) .,xxbos xxmaj this movie was a real milestone , it marked the end of xxmaj xxunk 's era . xxmaj like the part one is a snap - shot of 90s , this one is the reflection of , on the one hand , started changes of xxup xxunk internal and external policy . xxmaj of course , partly they were ( as usual ) just proclaimed changes , but it does n't matter in this case because , on the other hand , xxmaj brat-2 showed nation 's feelings and hopes of those days . xxmaj as far as i remember xxmaj xxunk himself said something like \" xxmaj the movie was just the answer to the state of public opinion \" . xxmaj also keep in mind it was time just after aggression of xxup us against xxmaj yugoslavia and time of victories of federal forces in the second xxmaj xxunk war - everyone still remembered the humiliation of the first war as well as all previous decade . xxmaj now you can imagine the eye we watched xxmaj xxunk with . xxmaj and you can understand what we felt \n",
       "  xxmaj the main message of the movie is xxmaj danila 's words : \" xxmaj so i think that the truth is the power : the one who has truth he is stronger \" . xxmaj this phrase has become a xxunk . xxmaj in fact , all the movie is about that : neither xxunk and criminal ( personified as \" xxmaj new xxmaj russians \" and xxmaj ukrainian bandits ) , nor money and hypocrisy ( xxmaj american smooth operators ) can defeat the truth . xxmaj the idea is shown with use of violence . xxmaj this point was subject of much criticism , but it 's certainly not the main thing in the film , at most the decoration for its message . xxmaj if you saw xxmaj brat-2 you would understand me . xxmaj another idea is that you can find good and sincere people in any country , any nation and any order . xxmaj it does n't matter what all damned governments and bigwigs do : good hearts will always find each other in this cruel world . xxmaj in addition , xxmaj brat-2 is full of sentences , including humorous , which became famous : the above - mentioned \" truth \" , \" xxmaj russians never desert their own in the war \" , \" xxmaj you bitches will answer to me for xxmaj xxunk ! \" and many others . \n",
       " \n",
       "  xxmaj so . xxmaj despite some rude episodes i disliked , despite ( i think ) excessive violence shown , i give it 10 of 10 . xxmaj xxunk deserves .,xxbos i 'm a fan of xxmaj columbo , especially on a rainy xxmaj saturday , and it was fun to see xxmaj oskar xxmaj werner after xxmaj fahrenheit xxunk , but this episode was very lacking . xxmaj the original plot and plot twists were obvious and could be guessed way in advance , even years before the modern detective shows of today . xxmaj but it was amusing to see the crazy couch patterns and \" modern \" electronics equipment and , of course , the mandatory suburbanite humor poking fun at modern art for sale . xxmaj the high - tech home is a xxmaj xxunk 's or xxmaj disney version of xxmaj xxunk , and fun to think of writers inventing those \" way - out gizmos \" . \n",
       " \n",
       "  xxmaj if its sunny outside , go play , as there are much better xxmaj columbo episodes . xxmaj still , we should be thankful for xxmaj cable xxup tv that these episodes are being broadcast .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /home/ubuntu/.fastai/data/imdb;\n",
       "\n",
       "Valid: LabelList (1999 items)\n",
       "x: LMTextList\n",
       "xxbos xxup ok , how 's this for xxunk this mean , rich old geezer leaves his estate to his adult children , all of them ungrateful losers , and two creepy servants , provided they spend the week in his spooky old house . xxmaj what happens that night will surprise only those who have n't seen a movie or television show before . xxmaj after a string of murders in which the victims look like they 're bleeding restaurant ketchup , we have a painfully obvious twist ending . xxmaj the cast is lead by some once respectable actors must have been desperate for their paychecks . xxmaj there are also a few second - tier actors who were rising at the time but long forgotten now . xxmaj as a result , the film generates all the drama and mystery of an episode of \" xxmaj matlock . \" i will give credit where it 's xxunk the closing scene is clever and amusing , if you 're still awake .,xxbos i know that i am probably two decades older than the target audience for \" xxmaj one xxmaj tree xxmaj hill \" . i saw this particular episode by accident . i think the subject matter of school shootings is very important . i just wished that the treatment here was more imaginative and , especially the final plot twist at the end of the episode , not so contrived . \n",
       " \n",
       "  xxmaj the only bright spot in this episode was the credible performance of xxmaj colin xxmaj xxunk as xxmaj jimmy xxmaj edwards , the distraught student who held his fellow students hostage . i felt that the actor was on an entirely different level than the others . xxmaj the stars and the supporting cast were very bland and uninteresting . \n",
       " \n",
       "  xxmaj at least with this episode , i kept thinking about how \" xxmaj xxunk : xxmaj the xxmaj next xxmaj generation \" did a much better job than \" xxmaj one xxmaj tree xxmaj hill \" . i noticed that the average age of the actors on \" xxmaj one xxmaj tree xxmaj hill \" is around 23 or 24 years old while the actors on xxmaj xxunk is closer to high school age . xxmaj sometimes when it comes to television shows or movies about teens or young adults , it depends not only on the script but the casting and the talent of the actors .,xxbos yeah its fun and the best xxmaj hitchcock i xxunk hate that xxunk is making it this is the one and only best no 1 i mean no one can change that good suspense and fun 1 for black and white xxmaj while this was n't xxmaj hitchcock 's first feature film , he refers to it as the one that set the pace for his later films , the first to show his vision , style , and bravura . xxmaj the most interesting thing about this film , other than its technical virtuosity and the horribly ineffective soundtrack , is the fact that it was n't supposed to end the way it did . xxmaj hitchcock wanted xxmaj the xxmaj lodger to be the killer , which would have made a more predictable film ( granted in 1926 audiences were n't spoiled by the great of the genre and everything could have been \" surprising \" if the right amount of suspense and tension were provided ) . xxmaj instead , there were pressures to let matinée idol xxmaj xxunk xxmaj novello out of the killer role , probably because people did n't want to picture xxmaj novello as a killer . xxmaj ironically , the fact xxmaj novello would n't end up as the killer made this film even better , a lot more interesting and compelling .,xxbos xxmaj one of my favourite films first saw it when i was about 10 , which probably tells you a lot about the type of humour . xxmaj although dated the humour definitely has a charm about it . xxmaj expect to see the usual xxmaj xxunk & xxmaj murdoch banter so popular in its day , with lots of interesting , quirky co - characters . xxmaj the lady with the parrot , the couple due to get married and are in trouble from ' her ' , and my favourite , the xxunk , \" xxmaj nobody knows where it comes from ... nobody knows where it goes .. \" xxmaj interestingly the ghost train was written by xxmaj arnold xxmaj ridley of xxmaj dads xxmaj army fame ( xxmaj private xxmaj godfrey the medic ) xxmaj watch it on a rainy xxmaj sunday afternoon after your lunch and smile .,xxbos i love xxmaj juan xxmaj piquer - xxmaj xxunk ! xxmaj he 's my absolute favorite bad - movie director and , throughout his whole career , he xxunk tried to cash in on simply every successful contemporary trend in the horror and fantasy genres . xxmaj after the big hit that was \" xxmaj superman \" , xxup xxunk made his own and hilarious \" xxmaj supersonic xxmaj man \" , he picked in on the violent slasher - movie madness with the insane \" xxmaj pieces \" and he really over - xxunk himself with \" xxmaj the xxmaj return of xxup e.t. \" , the unofficial and downright laughable sequel to xxmaj spielberg 's xxup sf - blockbuster . \" xxmaj the xxmaj rift \" is obviously inspired by the series of profitable underwater monster movies like \" xxmaj the xxmaj abyss \" and \" xxmaj xxunk xxmaj six \" . xxmaj from start to finish , you can amuse yourself by spotting all the stolen ideas and shameless rip - offs of these ( and other ) classics . xxmaj when a completely new and fancy type of submarine vanishes near the deep xxmaj xxunk rift , a second mission with u - boat designer xxmaj xxunk xxmaj hayes on board is sent out to investigate what really happened to xxmaj siren xxmaj one . xxmaj in the dark depths of the ocean , the rescue mission discovers an underwater cavern where the government secretly experiments with mutant sea - creatures . xxmaj the monsters are quite aggressive but there 's also the danger of a government enemy among the crew members ... \" xxmaj the xxmaj rift \" is a forgettable film , but it nevertheless has some ingenious  though very dodgy  monster models . xxmaj fans of blood and gore wo n't complain , neither , as the beastly attacks are quite gruesome and merciless . xxmaj the acting is very wooden although many of the cast names can definitely do better . xxmaj it 's xxunk that you simply enjoy the clichés and gory effects in the \" xxmaj the xxmaj rift \" because , if you start contemplating about the screenplay , you 'll find that it makes absolutely no sense .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /home/ubuntu/.fastai/data/imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(33860, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(33860, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=33860, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f34860d9730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/ubuntu/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(33860, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(33860, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=33860, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=None)\n",
       "alpha: 2.0\n",
       "beta: 1.0, MixedPrecision\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (18000 items)\n",
       "x: LMTextList\n",
       "xxbos xxmaj why do i give this 1974 porn movie 7 points ? xxmaj because i watched it . xxmaj and i found it hilarious ! xxmaj aliens , their weird spaceship , their weird helmets ... my xxmaj god , was that a sight . xxmaj and all what these desperate alien women need is semen from the earth . \n",
       " \n",
       "  xxmaj and where do they look for it ? xxmaj in upper xxmaj xxunk , xxmaj germany . xxmaj and that is where the main fun comes from : xxmaj in xxmaj europe ( and more so in xxmaj german - speaking countries ) , xxmaj xxunk is seen as a traditional and backward region . xxmaj and then the actors are so helpless with the alien women . xxmaj well , there have been films about people being unable to deal with women like the \" xxmaj american xxmaj pie \" series . \n",
       " \n",
       "  xxmaj but what this film achieved is a true , funny weirdness . xxmaj you constantly wonder how they came up with these crackpot ideas . xxmaj but it was 1974 , and looking back 35 years fills one with a kind of nostalgia . xxmaj you 've never seen a film like that . \n",
       " \n",
       "  xxmaj and if you do n't mind seeing the casual pubic hairs and breasts , watch it once . xxmaj it is a comedy essentially , not a porn flick .,xxbos xxmaj this film biography of early rock and roll star xxmaj buddy xxmaj holly ( 1936 - 1959 ) is a tour de force for xxmaj gary xxmaj busey . xxmaj the movie 's highlights are xxmaj busey 's stage performances where he plays guitar and sings xxmaj holly songs . xxmaj he brings such energy to the performances that xxmaj holly 's own filmed performances almost pale in comparison . xxmaj busey 's infectious xxunk grin lights up the screen , he creates a totally believable and winning personality and his xxmaj oscar nomination for best actor was well deserved . \n",
       " \n",
       "  xxmaj the film follows xxmaj holly 's career from growing up in xxmaj xxunk , xxmaj texas , to stardom and xxmaj new xxmaj york and his untimely death in a plane crash . xxmaj one thing i found interesting , if true , was xxmaj buddy 's driving ambition -- he had great plans to go beyond recording and performance to producing . xxmaj as young as he was he was already establishing himself as a shrewd businessman and definitely wanted to take things to a higher level . xxmaj we will never know if he would have ultimately catapulted his early success into a business brand like xxmaj the xxmaj rolling xxmaj stones . \n",
       " \n",
       "  xxmaj the lyrics of many of xxmaj holly 's songs are pretty adolescent ; read the lyrics for \" xxmaj peggy xxmaj sue \" or \" xxmaj oh xxmaj boy ! \" and you will see what i mean . xxmaj maybe to a great extent this explains his popularity with adolescent audiences , but his xxunk and stage performances surely account for his influence on groups to follow -- both xxmaj the xxmaj rolling xxmaj stones and xxmaj the xxmaj beatles have acknowledged his importance . \n",
       " \n",
       "  xxmaj clearly some liberties were taken for dramatic effect . xxmaj for example , i doubt that xxmaj holly ever punched out a producer in xxmaj nashville or that the audience at xxmaj new xxmaj york 's xxmaj apollo theater was so immediately xxunk as to be wildly dancing in the aisles . xxmaj if you are interested in getting closer to the truth , see the documentary \" xxmaj the xxmaj real xxmaj buddy xxmaj holly xxmaj story \" ( 1985 ) that is produced and hosted by a very relaxed and engaging xxmaj paul mccartney . xxmaj this contains interviews with xxmaj holly 's family , friends , and band - mates ( xxmaj holly 's musical brothers are not even mentioned in \" xxmaj the xxmaj buddy xxmaj holly xxmaj story \" ) . xxmaj members of other bands like xxmaj keith xxmaj richards and xxmaj don xxmaj everly also offer opinions and stories and there is footage of old xxmaj holly performances . xxmaj the mccartney production can stand on its own , but it makes an excellent companion piece to \" xxmaj the xxmaj buddy xxmaj holly xxmaj story \" and perhaps should be required viewing for anyone who watches the fictionalized story .,xxbos xxmaj now living in the late 1970 's , a former army xxmaj colonel / xxmaj scientist xxmaj robert xxmaj neville ( xxmaj oscar - xxmaj winner : xxmaj charleton xxmaj heston ) is living in a deserted xxmaj los xxmaj angeles . xxmaj after surviving a disastrous plague , which it 's been several years that xxmaj robert is alone and he thinks he is the only man alive in the entire world . xxmaj but when it turns dark outside ... there 's a group of cultists who called themselves \" xxmaj the xxmaj family \" ( xxmaj led by xxmaj anthony xxmaj zerbe ) , who got affected by the plague . \" xxmaj the xxmaj family \" are xxunk mutants , who ca n't be outside during the day expect night - time . xxmaj they also are trying to destroyed every technology or human , they could find . xxmaj which xxmaj robert battles with these freaks of nature nearly every night to survive . xxmaj but xxmaj robert finds out , he is not alone in the city . xxmaj when he meets a tough survivor xxmaj lisa ( xxmaj xxunk xxmaj cash ) and other humans are not turned by the virus . xxmaj now xxmaj robert finds another chance to find a cure against these monsters . xxmaj before it 's too late . \n",
       " \n",
       "  xxmaj directed by xxmaj boris xxmaj segal made an intriguing xxmaj science xxmaj fiction movie that has moments of action , suspense and some moments of comedy . xxmaj segal 's film is also visually striking , especially the wide empty streets of xxup l.a. but unfortunately the feature has some incredibly campy moments at rather tense sequences . xxmaj heston is very good at his role here . xxmaj which it is one of the reasons why \" xxmaj the xxmaj omega xxmaj man \" remain memorable for over the years . xxmaj although this is the second version of \" i xxmaj am xxmaj legend \" , xxmaj based on a novel by xxmaj richard xxmaj matheson ( xxmaj duel , a xxmaj stir of xxmaj echoes , xxmaj what xxmaj dreams xxmaj may xxmaj come ) . xxmaj first version was done in the 1960 's titled \" xxmaj the xxmaj last xxmaj man on xxmaj earth \" starring xxmaj vincent xxmaj price and last year 's \" i xxmaj am xxmaj legend \" starring xxmaj will xxmaj smith . xxmaj which these three films has the same premise but done completely different . xxmaj the book also inspired filmmaker xxmaj george xxup a. xxmaj romero to created flesh eating zombies in the classic \" xxmaj night of the xxmaj living xxmaj dead \" . xxmaj despite some serious flaws , \" xxmaj the xxmaj omega xxmaj man \" is still a good movie . xxmaj for those who are familiar with the recent adaptation \" i xxmaj am xxmaj legend \" and never seen this one . xxmaj this is worth checking out . xxmaj panavision . ( * * * ½ / xxrep 5 * ) .,xxbos xxmaj this movie was a real milestone , it marked the end of xxmaj xxunk 's era . xxmaj like the part one is a snap - shot of 90s , this one is the reflection of , on the one hand , started changes of xxup xxunk internal and external policy . xxmaj of course , partly they were ( as usual ) just proclaimed changes , but it does n't matter in this case because , on the other hand , xxmaj brat-2 showed nation 's feelings and hopes of those days . xxmaj as far as i remember xxmaj xxunk himself said something like \" xxmaj the movie was just the answer to the state of public opinion \" . xxmaj also keep in mind it was time just after aggression of xxup us against xxmaj yugoslavia and time of victories of federal forces in the second xxmaj xxunk war - everyone still remembered the humiliation of the first war as well as all previous decade . xxmaj now you can imagine the eye we watched xxmaj xxunk with . xxmaj and you can understand what we felt \n",
       "  xxmaj the main message of the movie is xxmaj danila 's words : \" xxmaj so i think that the truth is the power : the one who has truth he is stronger \" . xxmaj this phrase has become a xxunk . xxmaj in fact , all the movie is about that : neither xxunk and criminal ( personified as \" xxmaj new xxmaj russians \" and xxmaj ukrainian bandits ) , nor money and hypocrisy ( xxmaj american smooth operators ) can defeat the truth . xxmaj the idea is shown with use of violence . xxmaj this point was subject of much criticism , but it 's certainly not the main thing in the film , at most the decoration for its message . xxmaj if you saw xxmaj brat-2 you would understand me . xxmaj another idea is that you can find good and sincere people in any country , any nation and any order . xxmaj it does n't matter what all damned governments and bigwigs do : good hearts will always find each other in this cruel world . xxmaj in addition , xxmaj brat-2 is full of sentences , including humorous , which became famous : the above - mentioned \" truth \" , \" xxmaj russians never desert their own in the war \" , \" xxmaj you bitches will answer to me for xxmaj xxunk ! \" and many others . \n",
       " \n",
       "  xxmaj so . xxmaj despite some rude episodes i disliked , despite ( i think ) excessive violence shown , i give it 10 of 10 . xxmaj xxunk deserves .,xxbos i 'm a fan of xxmaj columbo , especially on a rainy xxmaj saturday , and it was fun to see xxmaj oskar xxmaj werner after xxmaj fahrenheit xxunk , but this episode was very lacking . xxmaj the original plot and plot twists were obvious and could be guessed way in advance , even years before the modern detective shows of today . xxmaj but it was amusing to see the crazy couch patterns and \" modern \" electronics equipment and , of course , the mandatory suburbanite humor poking fun at modern art for sale . xxmaj the high - tech home is a xxmaj xxunk 's or xxmaj disney version of xxmaj xxunk , and fun to think of writers inventing those \" way - out gizmos \" . \n",
       " \n",
       "  xxmaj if its sunny outside , go play , as there are much better xxmaj columbo episodes . xxmaj still , we should be thankful for xxmaj cable xxup tv that these episodes are being broadcast .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /home/ubuntu/.fastai/data/imdb;\n",
       "\n",
       "Valid: LabelList (1999 items)\n",
       "x: LMTextList\n",
       "xxbos xxup ok , how 's this for xxunk this mean , rich old geezer leaves his estate to his adult children , all of them ungrateful losers , and two creepy servants , provided they spend the week in his spooky old house . xxmaj what happens that night will surprise only those who have n't seen a movie or television show before . xxmaj after a string of murders in which the victims look like they 're bleeding restaurant ketchup , we have a painfully obvious twist ending . xxmaj the cast is lead by some once respectable actors must have been desperate for their paychecks . xxmaj there are also a few second - tier actors who were rising at the time but long forgotten now . xxmaj as a result , the film generates all the drama and mystery of an episode of \" xxmaj matlock . \" i will give credit where it 's xxunk the closing scene is clever and amusing , if you 're still awake .,xxbos i know that i am probably two decades older than the target audience for \" xxmaj one xxmaj tree xxmaj hill \" . i saw this particular episode by accident . i think the subject matter of school shootings is very important . i just wished that the treatment here was more imaginative and , especially the final plot twist at the end of the episode , not so contrived . \n",
       " \n",
       "  xxmaj the only bright spot in this episode was the credible performance of xxmaj colin xxmaj xxunk as xxmaj jimmy xxmaj edwards , the distraught student who held his fellow students hostage . i felt that the actor was on an entirely different level than the others . xxmaj the stars and the supporting cast were very bland and uninteresting . \n",
       " \n",
       "  xxmaj at least with this episode , i kept thinking about how \" xxmaj xxunk : xxmaj the xxmaj next xxmaj generation \" did a much better job than \" xxmaj one xxmaj tree xxmaj hill \" . i noticed that the average age of the actors on \" xxmaj one xxmaj tree xxmaj hill \" is around 23 or 24 years old while the actors on xxmaj xxunk is closer to high school age . xxmaj sometimes when it comes to television shows or movies about teens or young adults , it depends not only on the script but the casting and the talent of the actors .,xxbos yeah its fun and the best xxmaj hitchcock i xxunk hate that xxunk is making it this is the one and only best no 1 i mean no one can change that good suspense and fun 1 for black and white xxmaj while this was n't xxmaj hitchcock 's first feature film , he refers to it as the one that set the pace for his later films , the first to show his vision , style , and bravura . xxmaj the most interesting thing about this film , other than its technical virtuosity and the horribly ineffective soundtrack , is the fact that it was n't supposed to end the way it did . xxmaj hitchcock wanted xxmaj the xxmaj lodger to be the killer , which would have made a more predictable film ( granted in 1926 audiences were n't spoiled by the great of the genre and everything could have been \" surprising \" if the right amount of suspense and tension were provided ) . xxmaj instead , there were pressures to let matinée idol xxmaj xxunk xxmaj novello out of the killer role , probably because people did n't want to picture xxmaj novello as a killer . xxmaj ironically , the fact xxmaj novello would n't end up as the killer made this film even better , a lot more interesting and compelling .,xxbos xxmaj one of my favourite films first saw it when i was about 10 , which probably tells you a lot about the type of humour . xxmaj although dated the humour definitely has a charm about it . xxmaj expect to see the usual xxmaj xxunk & xxmaj murdoch banter so popular in its day , with lots of interesting , quirky co - characters . xxmaj the lady with the parrot , the couple due to get married and are in trouble from ' her ' , and my favourite , the xxunk , \" xxmaj nobody knows where it comes from ... nobody knows where it goes .. \" xxmaj interestingly the ghost train was written by xxmaj arnold xxmaj ridley of xxmaj dads xxmaj army fame ( xxmaj private xxmaj godfrey the medic ) xxmaj watch it on a rainy xxmaj sunday afternoon after your lunch and smile .,xxbos i love xxmaj juan xxmaj piquer - xxmaj xxunk ! xxmaj he 's my absolute favorite bad - movie director and , throughout his whole career , he xxunk tried to cash in on simply every successful contemporary trend in the horror and fantasy genres . xxmaj after the big hit that was \" xxmaj superman \" , xxup xxunk made his own and hilarious \" xxmaj supersonic xxmaj man \" , he picked in on the violent slasher - movie madness with the insane \" xxmaj pieces \" and he really over - xxunk himself with \" xxmaj the xxmaj return of xxup e.t. \" , the unofficial and downright laughable sequel to xxmaj spielberg 's xxup sf - blockbuster . \" xxmaj the xxmaj rift \" is obviously inspired by the series of profitable underwater monster movies like \" xxmaj the xxmaj abyss \" and \" xxmaj xxunk xxmaj six \" . xxmaj from start to finish , you can amuse yourself by spotting all the stolen ideas and shameless rip - offs of these ( and other ) classics . xxmaj when a completely new and fancy type of submarine vanishes near the deep xxmaj xxunk rift , a second mission with u - boat designer xxmaj xxunk xxmaj hayes on board is sent out to investigate what really happened to xxmaj siren xxmaj one . xxmaj in the dark depths of the ocean , the rescue mission discovers an underwater cavern where the government secretly experiments with mutant sea - creatures . xxmaj the monsters are quite aggressive but there 's also the danger of a government enemy among the crew members ... \" xxmaj the xxmaj rift \" is a forgettable film , but it nevertheless has some ingenious  though very dodgy  monster models . xxmaj fans of blood and gore wo n't complain , neither , as the beastly attacks are quite gruesome and merciless . xxmaj the acting is very wooden although many of the cast names can definitely do better . xxmaj it 's xxunk that you simply enjoy the clichés and gory effects in the \" xxmaj the xxmaj rift \" because , if you start contemplating about the screenplay , you 'll find that it makes absolutely no sense .\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: /home/ubuntu/.fastai/data/imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(33860, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(33860, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=33860, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f34860d9730>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/ubuntu/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(33860, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(33860, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=33860, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=None)\n",
       "loss_scale: 131072\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(33860, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(33860, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=33860, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_lm_nltk.load('fit_1_nltk')\n",
    "learn_lm_spacy.load('fit_1_spacy')\n",
    "learn_lm_sklearn.load('fit_1_sklearn')\n",
    "learn_lm_full.load('fit_1_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the fine-tuning, we can then unfreeze and launch a new training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.067201</td>\n",
       "      <td>5.103529</td>\n",
       "      <td>0.245249</td>\n",
       "      <td>12:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.968618</td>\n",
       "      <td>5.008870</td>\n",
       "      <td>0.250998</td>\n",
       "      <td>12:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.838385</td>\n",
       "      <td>4.955785</td>\n",
       "      <td>0.255924</td>\n",
       "      <td>12:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.696393</td>\n",
       "      <td>4.938035</td>\n",
       "      <td>0.257160</td>\n",
       "      <td>12:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.640994</td>\n",
       "      <td>4.938385</td>\n",
       "      <td>0.257317</td>\n",
       "      <td>12:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm_nltk.unfreeze()\n",
    "\n",
    "learn_lm_nltk.fit_one_cycle(5, lr, moms=(0.8,0.7))\n",
    "\n",
    "learn_lm_nltk.save('fine_tuned_nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.043610</td>\n",
       "      <td>5.085727</td>\n",
       "      <td>0.254575</td>\n",
       "      <td>12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.928919</td>\n",
       "      <td>4.997142</td>\n",
       "      <td>0.260042</td>\n",
       "      <td>12:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.804254</td>\n",
       "      <td>4.944851</td>\n",
       "      <td>0.263992</td>\n",
       "      <td>12:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.688810</td>\n",
       "      <td>4.928445</td>\n",
       "      <td>0.265249</td>\n",
       "      <td>12:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.620386</td>\n",
       "      <td>4.929239</td>\n",
       "      <td>0.265123</td>\n",
       "      <td>12:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm_spacy.unfreeze()\n",
    "\n",
    "learn_lm_spacy.fit_one_cycle(5, lr, moms=(0.8,0.7))\n",
    "\n",
    "learn_lm_spacy.save('fine_tuned_spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.022640</td>\n",
       "      <td>5.075490</td>\n",
       "      <td>0.253841</td>\n",
       "      <td>12:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.932579</td>\n",
       "      <td>4.983237</td>\n",
       "      <td>0.260333</td>\n",
       "      <td>12:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.797781</td>\n",
       "      <td>4.935812</td>\n",
       "      <td>0.263406</td>\n",
       "      <td>12:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.664725</td>\n",
       "      <td>4.918611</td>\n",
       "      <td>0.265124</td>\n",
       "      <td>12:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.602065</td>\n",
       "      <td>4.919520</td>\n",
       "      <td>0.265347</td>\n",
       "      <td>12:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm_sklearn.unfreeze()\n",
    "\n",
    "learn_lm_sklearn.fit_one_cycle(5, lr, moms=(0.8,0.7))\n",
    "\n",
    "learn_lm_sklearn.save('fine_tuned_sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.931436</td>\n",
       "      <td>3.936269</td>\n",
       "      <td>0.300083</td>\n",
       "      <td>19:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.867537</td>\n",
       "      <td>3.866182</td>\n",
       "      <td>0.307320</td>\n",
       "      <td>19:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.757106</td>\n",
       "      <td>3.826124</td>\n",
       "      <td>0.311961</td>\n",
       "      <td>19:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.633934</td>\n",
       "      <td>3.807157</td>\n",
       "      <td>0.314501</td>\n",
       "      <td>19:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.571203</td>\n",
       "      <td>3.805984</td>\n",
       "      <td>0.314833</td>\n",
       "      <td>19:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_lm_full.unfreeze()\n",
    "\n",
    "learn_lm_full.fit_one_cycle(5, lr, moms=(0.8,0.7))\n",
    "\n",
    "learn_lm_full.save('fine_tuned_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_lm_nltk.save_encoder('fine_tuned_enc_nltk')\n",
    "learn_lm_spacy.save_encoder('fine_tuned_enc_spacy')\n",
    "learn_lm_sklearn.save_encoder('fine_tuned_enc_sklearn')\n",
    "learn_lm_full.save_encoder('fine_tuned_enc_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_c_nltk = text_classifier_learner(data_cl_nltk, AWD_LSTM, drop_mult=0.3).to_fp16()\n",
    "learn_c_nltk.load_encoder('fine_tuned_enc_nltk')\n",
    "learn_c_nltk.freeze()\n",
    "\n",
    "learn_c_spacy = text_classifier_learner(data_cl_spacy, AWD_LSTM, drop_mult=0.3).to_fp16()\n",
    "learn_c_spacy.load_encoder('fine_tuned_enc_spacy')\n",
    "learn_c_spacy.freeze()\n",
    "\n",
    "learn_c_sklearn = text_classifier_learner(data_cl_sklearn, AWD_LSTM, drop_mult=0.3).to_fp16()\n",
    "learn_c_sklearn.load_encoder('fine_tuned_enc_sklearn')\n",
    "learn_c_sklearn.freeze()\n",
    "\n",
    "learn_c_full = text_classifier_learner(data_cl_full, AWD_LSTM, drop_mult=0.3).to_fp16()\n",
    "learn_c_full.load_encoder('fine_tuned_enc_full')\n",
    "learn_c_full.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.326914</td>\n",
       "      <td>0.260933</td>\n",
       "      <td>0.891440</td>\n",
       "      <td>10:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_nltk.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n",
    "\n",
    "learn_c_nltk.save('first_nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.280634</td>\n",
       "      <td>0.226322</td>\n",
       "      <td>0.910080</td>\n",
       "      <td>12:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_nltk.freeze_to(-2)\n",
    "learn_c_nltk.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_nltk.save('2nd_nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.231860</td>\n",
       "      <td>0.190027</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>18:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_nltk.freeze_to(-3)\n",
    "learn_c_nltk.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_nltk.save('3rd_nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.191383</td>\n",
       "      <td>0.184940</td>\n",
       "      <td>0.928160</td>\n",
       "      <td>24:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.173254</td>\n",
       "      <td>0.187098</td>\n",
       "      <td>0.929320</td>\n",
       "      <td>21:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_nltk.unfreeze()\n",
    "learn_c_nltk.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_nltk.save('clas_nltk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spaCy stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.347636</td>\n",
       "      <td>0.271195</td>\n",
       "      <td>0.886520</td>\n",
       "      <td>10:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_spacy.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n",
    "\n",
    "learn_c_spacy.save('first_spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.287518</td>\n",
       "      <td>0.232540</td>\n",
       "      <td>0.906080</td>\n",
       "      <td>11:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_spacy.freeze_to(-2)\n",
    "learn_c_spacy.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_spacy.save('2nd_spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.194601</td>\n",
       "      <td>0.921520</td>\n",
       "      <td>20:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_spacy.freeze_to(-3)\n",
    "learn_c_spacy.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_spacy.save('3rd_spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.203296</td>\n",
       "      <td>0.195634</td>\n",
       "      <td>0.923520</td>\n",
       "      <td>26:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.191713</td>\n",
       "      <td>0.184717</td>\n",
       "      <td>0.926640</td>\n",
       "      <td>21:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_spacy.unfreeze()\n",
    "learn_c_spacy.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_spacy.save('clas_spacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.340221</td>\n",
       "      <td>0.269864</td>\n",
       "      <td>0.890080</td>\n",
       "      <td>10:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_sklearn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n",
    "\n",
    "learn_c_sklearn.save('first_sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.290730</td>\n",
       "      <td>0.228926</td>\n",
       "      <td>0.908760</td>\n",
       "      <td>13:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_sklearn.freeze_to(-2)\n",
    "learn_c_sklearn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_sklearn.save('2nd_sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.241448</td>\n",
       "      <td>0.193604</td>\n",
       "      <td>0.926040</td>\n",
       "      <td>17:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_sklearn.freeze_to(-3)\n",
    "learn_c_sklearn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_sklearn.save('3rd_sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.197448</td>\n",
       "      <td>0.185936</td>\n",
       "      <td>0.928840</td>\n",
       "      <td>22:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.189658</td>\n",
       "      <td>0.184257</td>\n",
       "      <td>0.929280</td>\n",
       "      <td>21:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_sklearn.unfreeze()\n",
    "learn_c_sklearn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_sklearn.save('clas_sklearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.318659</td>\n",
       "      <td>0.262543</td>\n",
       "      <td>0.892480</td>\n",
       "      <td>10:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_full.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n",
    "\n",
    "learn_c_full.save('first_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.274875</td>\n",
       "      <td>0.219725</td>\n",
       "      <td>0.911960</td>\n",
       "      <td>13:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_full.freeze_to(-2)\n",
    "learn_c_full.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_full.save('2nd_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.214808</td>\n",
       "      <td>0.179198</td>\n",
       "      <td>0.930200</td>\n",
       "      <td>20:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_full.freeze_to(-3)\n",
    "learn_c_full.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_full.save('3rd_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.173227</td>\n",
       "      <td>0.173576</td>\n",
       "      <td>0.934240</td>\n",
       "      <td>20:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.156472</td>\n",
       "      <td>0.173468</td>\n",
       "      <td>0.934320</td>\n",
       "      <td>25:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_c_full.unfreeze()\n",
    "learn_c_full.fit_one_cycle(2, slice(1e-3/(2.6**4), 1e-3), moms=(0.8,0.7))\n",
    "\n",
    "learn_c_full.save('clas_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 1.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stopwords_types = ['NLTK', 'spaCy', 'sklearn', 'None']\n",
    "cl_results = [0.929320, 0.926640, 0.929280, 0.934320]\n",
    "lm_results = [0.257317, 0.265123, 0.265347, 0.314833]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n",
    "sns.barplot(x=stopwords_types, y=lm_results, ax=ax[0])\n",
    "ax[0].set_title(\"Language model\")\n",
    "ax[0].set_xlabel(\"Stop Words Removed\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "sns.barplot(x=stopwords_types, y=cl_results, ax=ax[1])\n",
    "ax[1].set_title(\"Classifier model\")\n",
    "ax[1].set_xlabel(\"Stop Words Removed\")\n",
    "ax[1].set_ylim([0.7, 1.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
